* Administrative matters

- course materials [[https://github.com/ionescu/Machine_Learning_2019][on GitHub]]
  - lectures notes will generally be available after the lecture, though drafts may appear before
  - exercises will also be posted on GitHub

- register for CATS points
  - assessment: homework to be handed in a the next meeting (or sent to me by email, or to PPWeekly)
  - every piece of homework is pass or fail

- course takes place Saturdays 10:00-12:30 at Ewert House
  - exceptions: *no class* on the *4th of May* and *15th of June*!

- main text: /Machine Learning/, Tom Mitchell, 1997
  - there are a couple of copies available in the ContEd library
  - you can buy it used for under 15 GBP on [[https://www.amazon.co.uk/gp/offer-listing/1259096955/ref=sr_1_3_olp?keywords=mitchell+machine+learning&qid=1555784813&s=gateway&sr=8-3][Amazon]]
  - but you should be able to complete the course using only the lecture notes

* Introduction

- types of learning:
  - by rote
  - conditioning
  - from experience
  - any others?

- reasons for /machine learning/:
  - programming is hard, it would be better if computers learnt by themselves
  - to study human learning (and intelligence)
    - perhaps we could then improve our own abilities to learn and to teach

- two main approaches:
  - modelling how we think and learn, without caring about the underlying physiological mechanisms
  - modelling the underlying physiological mechanism, without caring how they lead to thinking and learning

- *Definition* (Mitchell, p. 2) A computer program is said to *learn*
  from experience /E/ with respect to some class of tasks /T/ and
  performance measure /P/, if its performance at tasks in /T/, as
  measured by /P/, improves with experience /E/.
  - how can we understand this mathematically?
    - for example, by representing the various elements using sets and functions
    - the most difficult to represent in this way appears to be /the task/

- A preliminary mathematical representation:
  - the set of tasks: =Task = In -> Out=
  - the set of experiences: ```Experience = List E```{.haskell}
  - measure of performance: $Perf : Task \to List In \to \mathb{R}$
    - important: what we measure is of the same nature as the experience
  - machine learning system: $ml : E \to T$
  - for all $es_1, es_2$ we have
    $$Perf (ml es_1) inputs <= Perf (ml (es_1 ++ es_2)) inputs$$

- Example: handwriting recognition
  - $T = Handwritten \to Standard$
  - $E = List (Handwritten, Standard)$
  - $P : E \to \mathbb{R}$

- Example: checkers learning
  - the task: $T : Board \to Move$
  - experience: 



